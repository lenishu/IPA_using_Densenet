{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkJV1rHx9IIGLmjw+MkV3c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lenishu/IPA_using_Densenet/blob/main/testing_5_Densenet_121.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9z4yj7J4cRk",
        "outputId": "467f2ad8-eed5-4b54-ab35-2868ba1d158d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted. Files will be saved to /content/drive/My Drive/DenseNet_Pruning_Verification\n",
            "Google Drive is mounted. All verification files will be saved to:\n",
            "  /content/drive/My Drive/DenseNet_Pruning_Verification\n",
            "Successfully wrote test file to Google Drive. File access is working correctly.\n",
            "Running DenseNet-121 pruning verification tests\n",
            "Created directory: /content/drive/My Drive/DenseNet_Pruning_Verification/pruning_verification_20250519_210609\n",
            "Creating base output directory: /content/drive/My Drive/DenseNet_Pruning_Verification/pruning_verification_20250519_210609\n",
            "Created directory: /content/drive/My Drive/DenseNet_Pruning_Verification/pruning_verification_20250519_210609/tiny_pruning\n",
            "Created directory: /content/drive/My Drive/DenseNet_Pruning_Verification/pruning_verification_20250519_210609/medium_pruning\n",
            "\n",
            "Loading mnist dataset for verification...\n",
            "\n",
            "Creating baseline model to calculate baseline CE...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50s/step - accuracy: 0.1100 - categorical_crossentropy: 2.3019 - loss: 2.3019\n",
            "Baseline CE (CEo): 2.3019018173217773\n",
            "\n",
            "===== TEST 1: Tiny pruning (exactly 10 parameters) =====\n",
            "Created directory: /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1\n",
            "\n",
            "Running experiment: mnist, parameter_mask, P% = 0.00013514851, Run #1\n",
            "Verification files will be saved to: /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1\n",
            "Using CE threshold ln(10) = 2.3026 for mnist\n",
            "Test mode: Pruning exactly 10 parameters (approx. 0.0001351485% of 7,399,616 parameters)\n",
            "Total trainable parameters: 7,399,616\n",
            "Parameters to prune: 10 (0.00013514851%)\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "Batch 10: Train Acc=0.3049, Test Acc=0.1400, Test CE=6.7716\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 1 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 1 pruned weights became non-zero\n",
            "VERIFICATION SUCCESSFUL: All pruned indices remained zero across all batches.\n",
            "P0.00013514851 Run #1 - Test Accuracy: 0.1400, IPA × 1000: 0.000000, CE above threshold (IPA set to 0)\n",
            "\n",
            "===== TEST 2: Medium pruning (30%) =====\n",
            "Created directory: /content/drive/My Drive/DenseNet_Pruning_Verification/P30_run1\n",
            "\n",
            "Running experiment: mnist, parameter_mask, P% = 30, Run #1\n",
            "Verification files will be saved to: /content/drive/My Drive/DenseNet_Pruning_Verification/P30_run1\n",
            "Using CE threshold ln(10) = 2.3026 for mnist\n",
            "Pruning 2,219,884 parameters (30.00% of 7,399,616 parameters)\n",
            "Total trainable parameters: 7,399,616\n",
            "Parameters to prune: 2,219,884 (30%)\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 11016 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 11074 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 11010 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 11074 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10903 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 11100 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 11103 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 11043 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 11094 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10813 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 11016 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10913 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10938 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10971 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 11077 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 11126 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10978 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11183 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 11007 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 11073 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11218 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10977 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10975 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 11018 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 11006 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 11030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10992 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 11037 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10888 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 11076 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 11053 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 11034 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 11075 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10811 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 11016 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10885 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10925 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10953 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 11077 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10950 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11162 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10995 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11191 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10977 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10966 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 11006 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10907 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 11004 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10940 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10976 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10856 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 11039 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10969 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 11065 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10768 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10947 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10917 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10914 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10941 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 11050 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 11098 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10965 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11126 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 11012 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 11046 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11157 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10937 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10862 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10947 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10914 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10970 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10762 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10995 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 11041 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10926 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 11039 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10705 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10921 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10867 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10883 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10889 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10999 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 11063 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10937 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11143 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10983 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11207 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10929 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10905 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10832 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10852 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10896 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10802 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10886 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10757 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10891 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 11012 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10816 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10944 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10735 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10828 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10818 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10840 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10879 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10993 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 11030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10912 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11062 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10917 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 11032 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11147 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10951 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10881 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10737 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10778 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10827 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10791 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10577 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10871 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10882 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10921 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10666 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10840 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10784 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10801 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10828 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10964 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10952 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10832 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 10972 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10907 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10980 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11115 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10860 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10877 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10873 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10795 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10921 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10803 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10837 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10668 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10907 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10918 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10823 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10942 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10649 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10807 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10742 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10711 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10691 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10903 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10947 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10818 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11058 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10876 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10905 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11138 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10927 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10920 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10866 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10819 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10832 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10843 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10821 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10693 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10841 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10965 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10948 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10611 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10841 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10709 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10770 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10755 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10910 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10961 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11026 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10960 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11050 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10848 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10919 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10820 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10727 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10805 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10756 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10745 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10580 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10814 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10967 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10864 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10582 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10831 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10721 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10728 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10856 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10851 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11073 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10867 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10900 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11038 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10896 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10864 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "Batch 10: Train Acc=0.3232, Test Acc=0.0900, Test CE=2.3083\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10804 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10827 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10848 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10744 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10842 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10647 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10788 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10882 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10845 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10920 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10564 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10774 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10708 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10749 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10813 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10821 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10913 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10870 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 10970 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10890 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10970 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11059 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10890 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10864 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10952 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10831 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10855 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10789 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10899 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10685 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10762 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10953 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10814 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10940 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10569 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10760 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10679 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10731 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10805 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10843 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10942 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10876 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11047 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10864 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10915 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11085 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10877 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10887 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10896 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10849 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10890 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10797 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10802 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10673 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10825 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10795 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10973 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10588 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10829 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10771 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10854 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10901 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10968 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10951 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11077 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10851 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10936 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11075 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10860 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10799 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10730 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10726 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10676 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10776 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10594 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10732 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10720 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10776 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10914 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10556 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10760 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10722 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10703 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10695 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10846 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10858 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10790 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 11006 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10815 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10905 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11034 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10828 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10795 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "CE dropped below threshold (2.3026) at batch 14 (CE = 2.2909)\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10728 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10814 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10643 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10798 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10796 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10837 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10897 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10560 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10778 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10760 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10741 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10836 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 10988 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10855 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10861 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 11025 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10792 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10868 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10796 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10643 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10839 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10673 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10669 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10657 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10769 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10829 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10870 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10956 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10559 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10732 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10695 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10729 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10750 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10895 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 10954 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10864 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10866 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 10980 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10829 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10844 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 0: 2767 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 1: 2490 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 2: 11145 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 3: 3710 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 4: 11069 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 5: 5014 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 6: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 7: 6152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 8: 11102 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 9: 7381 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 10: 10945 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 11: 8508 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 12: 11111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 13: 9758 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 14: 4826 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 15: 11153 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 16: 6148 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 17: 11105 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 18: 7300 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 19: 11152 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 20: 8781 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 21: 11204 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 22: 9800 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 23: 11079 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 24: 11052 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 25: 11064 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 26: 12239 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 27: 11171 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 28: 13535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 29: 11072 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 30: 14702 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 31: 10833 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 32: 15863 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 33: 11002 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 34: 17348 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 35: 11246 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 36: 18440 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 37: 11027 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 38: 39166 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 39: 9878 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 40: 10693 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 41: 11045 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 42: 10597 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 43: 12321 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 44: 10757 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 45: 13600 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 46: 10639 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 47: 14834 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 48: 10662 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 49: 16011 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 50: 10578 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 51: 17084 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 52: 10802 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 53: 18568 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 54: 10686 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 55: 19593 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 56: 10716 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 57: 20955 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 58: 10844 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 59: 22170 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 60: 10502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 61: 23422 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 62: 10674 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 63: 24765 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 64: 10601 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 65: 25892 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 66: 10567 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 67: 27030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 68: 10744 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 69: 28489 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 70: 10755 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 71: 29680 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 72: 10857 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 73: 30700 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 74: 10751 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 75: 32083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 76: 10966 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 77: 33083 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 78: 10795 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 79: 34111 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 80: 10822 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 81: 35812 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 82: 10948 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 83: 36911 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 84: 10807 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 85: 38237 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 86: 10769 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 87: 157502 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 88: 19554 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 89: 1235 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 90: 20994 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 91: 1198 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 92: 22189 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 93: 1230 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 94: 23498 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 95: 1140 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 96: 24392 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 97: 1209 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 98: 25584 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 99: 1216 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 100: 26743 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 101: 1297 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 102: 28265 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 103: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 104: 29689 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 105: 1257 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 106: 30537 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 107: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 108: 32089 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 109: 1200 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 110: 33030 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 111: 1190 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 112: 34117 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 113: 1254 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 114: 35535 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 115: 1225 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 116: 36761 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 117: 1217 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 118: 38097 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 119: 1244 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 120: 157507 pruned weights became non-zero\n",
            "WARNING: Batch 0, Layer 121: 1503 pruned weights became non-zero\n",
            "VERIFICATION SUCCESSFUL: All pruned indices remained zero across all batches.\n",
            "P30 Run #1 - Test Accuracy: 0.0800, IPA × 1000: 0.000254, CE below threshold\n",
            "\n",
            "Verification tests complete! Results saved to /content/drive/My Drive/DenseNet_Pruning_Verification/pruning_verification_20250519_210609\n",
            "Results are available in your Google Drive at: /content/drive/My Drive/DenseNet_Pruning_Verification\n",
            "Check the verification summary and individual test directories for detailed results.\n",
            "Created comparison shell script: /content/drive/My Drive/DenseNet_Pruning_Verification/pruning_verification_20250519_210609/compare_indices.sh\n",
            "This script is available in your Google Drive for download and use on a Linux machine.\n",
            "\n",
            "===== NOTE ABOUT WARNINGS =====\n",
            "You may see warnings about 'pruned weights became non-zero'. This is normal and expected.\n",
            "These warnings indicate that gradient updates tried to change pruned weights,\n",
            "but our MaskWeightsCallback detected this and re-applied the mask to set them back to zero.\n",
            "The verification files will confirm that all pruned weights remained zero after the callback ran.\n",
            "\n",
            "\n",
            "Comparing pruned indices in /content/drive/My Drive/DenseNet_Pruning_Verification/pruning_verification_20250519_210609/tiny_pruning/P0.00013514851_run1\n",
            "Reference file /content/drive/My Drive/DenseNet_Pruning_Verification/pruning_verification_20250519_210609/tiny_pruning/P0.00013514851_run1/prune-indices_batch-0.txt not found!\n",
            "\n",
            "Verification report created: /content/drive/My Drive/DenseNet_Pruning_Verification/pruning_verification_20250519_210609/pruning_verification_report.txt\n",
            "\n",
            "WARNING: Some expected files were not found where expected.\n",
            "Running a file search to locate verification files...\n",
            "\n",
            "Searching for verification files...\n",
            "Searching in Google Drive: /content/drive/My Drive\n",
            "Searching locally: .\n",
            "Found 52 verification-related files.\n",
            "First 10 files found:\n",
            "  1. /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1/prune-indices_batch-0.txt\n",
            "  2. /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1/pruned_indices.csv\n",
            "  3. /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1/all-zero-indices_batch-0.txt\n",
            "  4. /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1/all-zero-indices_batch-0.csv\n",
            "  5. /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1/prune-indices_batch-1.txt\n",
            "  6. /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1/all-zero-indices_batch-1.txt\n",
            "  7. /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1/all-zero-indices_batch-1.csv\n",
            "  8. /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1/prune-indices_batch-2.txt\n",
            "  9. /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1/all-zero-indices_batch-2.txt\n",
            "  10. /content/drive/My Drive/DenseNet_Pruning_Verification/P0.00013514851_run1/all-zero-indices_batch-2.csv\n",
            "  ... and 42 more files.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "DenseNet-121 Pruning Verification\n",
        "\n",
        "This script provides tools to verify that parameter mask pruning is working correctly\n",
        "in a DenseNet-121 model. It tracks pruned weight indices across multiple training batches\n",
        "to ensure they remain zero throughout training.\n",
        "\n",
        "The script runs two verification tests:\n",
        "1. A tiny pruning test (exactly 10 parameters) for easy inspection\n",
        "2. A medium pruning test (30% of weights) to test at scale\n",
        "\n",
        "For each test, it saves the pruned indices after initial pruning and after batches 1, 2, and 3,\n",
        "then compares them to verify that pruning is working correctly.\n",
        "\n",
        "All verification files are saved to Google Drive.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, ReLU, Conv2D, Dense, MaxPool2D, AvgPool2D, GlobalAvgPool2D, Concatenate\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist, cifar10, cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Model\n",
        "import math\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive (this will work in Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    GOOGLE_DRIVE_MOUNTED = True\n",
        "    GOOGLE_DRIVE_BASE_PATH = \"/content/drive/My Drive/DenseNet_Pruning_Verification\"\n",
        "    # Create base directory in Google Drive if it doesn't exist\n",
        "    os.makedirs(GOOGLE_DRIVE_BASE_PATH, exist_ok=True)\n",
        "    print(f\"Google Drive mounted. Files will be saved to {GOOGLE_DRIVE_BASE_PATH}\")\n",
        "except ImportError:\n",
        "    GOOGLE_DRIVE_MOUNTED = False\n",
        "    GOOGLE_DRIVE_BASE_PATH = None\n",
        "    print(\"Not running in Colab or Google Drive not available. Files will be saved locally.\")\n",
        "\n",
        "# Configuration\n",
        "BATCH_SIZE_TRAIN = 64\n",
        "BATCH_SIZE_TEST = 256\n",
        "LEARNING_RATE = 0.1\n",
        "EPOCHS_PER_RUN = 1\n",
        "\n",
        "# Function to get output directory path (either on Google Drive or locally)\n",
        "def get_output_dir(local_dir, create=True):\n",
        "    \"\"\"\n",
        "    Get the output directory path (either on Google Drive or locally)\n",
        "\n",
        "    Parameters:\n",
        "    local_dir -- Local directory path\n",
        "    create -- Whether to create the directory if it doesn't exist\n",
        "\n",
        "    Returns:\n",
        "    Full path to the directory\n",
        "    \"\"\"\n",
        "    if GOOGLE_DRIVE_MOUNTED:\n",
        "        # Extract the base name from the local path if it's a full path\n",
        "        if os.path.isabs(local_dir):\n",
        "            base_name = os.path.basename(local_dir)\n",
        "        else:\n",
        "            base_name = local_dir\n",
        "\n",
        "        # Construct the full path on Google Drive\n",
        "        full_path = os.path.join(GOOGLE_DRIVE_BASE_PATH, base_name)\n",
        "    else:\n",
        "        full_path = local_dir\n",
        "\n",
        "    # Create the directory if requested\n",
        "    if create:\n",
        "        os.makedirs(full_path, exist_ok=True)\n",
        "        print(f\"Created directory: {full_path}\")\n",
        "\n",
        "    return full_path\n",
        "\n",
        "# Function to load and preprocess datasets\n",
        "def load_dataset(dataset_name):\n",
        "    if dataset_name == 'mnist':\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "        # Reshape to add channel dimension and resize to 32x32\n",
        "        x_train = np.pad(x_train, ((0, 0), (2, 2), (2, 2)), 'constant')\n",
        "        x_test = np.pad(x_test, ((0, 0), (2, 2), (2, 2)), 'constant')\n",
        "        x_train = np.expand_dims(x_train, axis=-1)\n",
        "        x_test = np.expand_dims(x_test, axis=-1)\n",
        "        # Repeat the channel to match the 3-channel input expected by DenseNet\n",
        "        x_train = np.repeat(x_train, 3, axis=-1)\n",
        "        x_test = np.repeat(x_test, 3, axis=-1)\n",
        "        num_classes = 10\n",
        "    elif dataset_name == 'fashion_mnist':\n",
        "        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "        x_train = np.pad(x_train, ((0, 0), (2, 2), (2, 2)), 'constant')\n",
        "        x_test = np.pad(x_test, ((0, 0), (2, 2), (2, 2)), 'constant')\n",
        "        x_train = np.expand_dims(x_train, axis=-1)\n",
        "        x_test = np.expand_dims(x_test, axis=-1)\n",
        "        x_train = np.repeat(x_train, 3, axis=-1)\n",
        "        x_test = np.repeat(x_test, 3, axis=-1)\n",
        "        num_classes = 10\n",
        "    elif dataset_name == 'cifar10':\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        num_classes = 10\n",
        "    elif dataset_name == 'cifar100':\n",
        "        (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "        num_classes = 100\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
        "\n",
        "    # Normalize data\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # Convert class vectors to binary class matrices\n",
        "    y_train = to_categorical(y_train, num_classes)\n",
        "    y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test), num_classes\n",
        "\n",
        "# Define DenseNet-121 architecture\n",
        "def bn_rl_conv(x, filters, kernel_size):\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
        "    return x\n",
        "\n",
        "def dense_block(tensor, k, reps):\n",
        "    for _ in range(reps):\n",
        "        x = bn_rl_conv(tensor, filters=4 * k, kernel_size=1)\n",
        "        x = bn_rl_conv(x, filters=k, kernel_size=3)\n",
        "        tensor = Concatenate()([tensor, x])\n",
        "    return tensor\n",
        "\n",
        "def transition_layer(x, theta):\n",
        "    f = int(tf.keras.backend.int_shape(x)[-1] * theta)\n",
        "    x = bn_rl_conv(x, filters=f, kernel_size=1)\n",
        "    x = AvgPool2D(pool_size=2, strides=2, padding='same')(x)\n",
        "    return x\n",
        "\n",
        "def create_densenet121(input_shape, num_classes, k=32, theta=0.5):\n",
        "    # DenseNet-121 has repetitions [6, 12, 24, 16]\n",
        "    repetitions = [6, 12, 24, 16]\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(2 * k, 7, strides=2, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPool2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "    for reps in repetitions:\n",
        "        x = dense_block(x, k, reps)\n",
        "        x = transition_layer(x, theta)\n",
        "\n",
        "    x = GlobalAvgPool2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "\n",
        "# Create a custom callback to enforce the mask during training\n",
        "# Modified MaskWeightsCallback with pre-mask zero indices tracking\n",
        "class MaskWeightsCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, masks, layer_indices, pruned_indices_per_layer, all_pruned_flat_indices, output_dir):\n",
        "        super().__init__()\n",
        "        self.masks = masks\n",
        "        self.layer_indices = layer_indices\n",
        "        self.pruned_indices_per_layer = pruned_indices_per_layer\n",
        "        self.all_pruned_flat_indices = all_pruned_flat_indices\n",
        "        self.output_dir = output_dir\n",
        "        self.batch_count = 0\n",
        "        self.max_batches_to_verify = 4  # Check up to batch 3\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        # This is called when the model starts training, ensuring the model is available\n",
        "        # Save zero indices for batch 0 here\n",
        "        self.save_all_zero_indices(0)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        # Before applying mask, save current zero weights\n",
        "        self.save_pre_mask_zero_indices(self.batch_count)\n",
        "\n",
        "        # Apply masks after each batch update\n",
        "        for i, layer_idx in enumerate(self.layer_indices):\n",
        "            layer = self.model.layers[layer_idx]\n",
        "            weights = layer.get_weights()\n",
        "\n",
        "            # Before applying mask, check if any pruned indices are non-zero\n",
        "            if self.batch_count < self.max_batches_to_verify:\n",
        "                # Check actual values at pruned indices\n",
        "                flat_weights = weights[0].flatten()\n",
        "                non_zero_pruned = []\n",
        "\n",
        "                for idx in self.pruned_indices_per_layer.get(i, []):\n",
        "                    if flat_weights[idx] != 0:\n",
        "                        non_zero_pruned.append((idx, flat_weights[idx]))\n",
        "\n",
        "                # Log any violations (pruned weights that became non-zero)\n",
        "                if non_zero_pruned:\n",
        "                    print(f\"WARNING: Batch {self.batch_count}, Layer {i}: {len(non_zero_pruned)} pruned weights became non-zero\")\n",
        "\n",
        "            # Apply mask (set pruned weights back to zero)\n",
        "            weights[0] = weights[0] * self.masks[i]\n",
        "            layer.set_weights(weights)\n",
        "\n",
        "        # Verify and save pruned indices after specific batches\n",
        "        # if self.batch_count in [1, 2, 3]:  # Check batches 1, 2, and 3\n",
        "        #     self.verify_pruning(self.batch_count)\n",
        "        #     self.save_all_zero_indices(self.batch_count)  # Save all zero indices for this batch\n",
        "\n",
        "        # self.batch_count += 1\n",
        "\n",
        "    def save_pre_mask_zero_indices(self, batch_num):\n",
        "        \"\"\"Save all indices that are zero BEFORE applying the mask\"\"\"\n",
        "        # Dictionary to store which indices are currently zero\n",
        "        current_zero_indices_per_layer = {}\n",
        "        all_current_zero_flat_indices = []\n",
        "\n",
        "        # Track total parameters for flat index calculation\n",
        "        params_so_far = 0\n",
        "\n",
        "        # Check each layer for zero weights before mask is applied\n",
        "        for i, layer_idx in enumerate(self.layer_indices):\n",
        "            layer = self.model.layers[layer_idx]\n",
        "            weights = layer.get_weights()[0]\n",
        "            flat_weights = weights.flatten()\n",
        "\n",
        "            # Find all indices that are zero\n",
        "            zero_indices = np.where(flat_weights == 0)[0]\n",
        "            current_zero_indices_per_layer[i] = sorted(zero_indices.tolist())\n",
        "\n",
        "            # Convert to flat indices across the entire model\n",
        "            flat_zero_indices = [idx + params_so_far for idx in zero_indices]\n",
        "            all_current_zero_flat_indices.extend(flat_zero_indices)\n",
        "\n",
        "            params_so_far += flat_weights.size\n",
        "\n",
        "        all_current_zero_flat_indices = sorted(all_current_zero_flat_indices)\n",
        "\n",
        "        # Write all zero indices to a separate file\n",
        "        with open(os.path.join(self.output_dir, f\"pre-mask-zero-indices_batch-{batch_num}.txt\"), 'w') as f:\n",
        "            f.write(f\"Batch {batch_num} - All Zero Weight Indices BEFORE Mask Application\\n\")\n",
        "            f.write(f\"=========================================================\\n\\n\")\n",
        "\n",
        "            # Write summary statistics\n",
        "            total_zero_indices = len(all_current_zero_flat_indices)\n",
        "            f.write(f\"Total zero weights before mask: {total_zero_indices}\\n\\n\")\n",
        "\n",
        "            # Write zero indices per layer\n",
        "            f.write(\"Zero indices per layer before mask:\\n\")\n",
        "            for layer_idx, indices in current_zero_indices_per_layer.items():\n",
        "                f.write(f\"Layer index {layer_idx}: {len(indices)} zero indices\\n\")\n",
        "\n",
        "                # For small numbers of indices, write them all\n",
        "                if len(indices) <= 20:\n",
        "                    f.write(f\"  {indices}\\n\")\n",
        "                else:\n",
        "                    # For larger sets, write first and last 10\n",
        "                    f.write(f\"  First 10: {indices[:10]}\\n\")\n",
        "                    f.write(f\"  Last 10: {indices[-10:]}\\n\")\n",
        "\n",
        "            # Write all flat indices\n",
        "            f.write(\"\\nAll zero flat indices before mask:\\n\")\n",
        "            f.write(f\"{all_current_zero_flat_indices}\\n\")\n",
        "\n",
        "            # Calculate how many match with originally pruned weights\n",
        "            original_pruned_set = set(self.all_pruned_flat_indices)\n",
        "            current_zero_set = set(all_current_zero_flat_indices)\n",
        "            naturally_zero = current_zero_set - original_pruned_set\n",
        "            still_pruned = current_zero_set.intersection(original_pruned_set)\n",
        "            no_longer_zero = original_pruned_set - current_zero_set\n",
        "\n",
        "            f.write(f\"\\nSummary statistics:\\n\")\n",
        "            f.write(f\"Originally pruned weights: {len(self.all_pruned_flat_indices)}\\n\")\n",
        "            f.write(f\"Currently zero weights before mask: {len(all_current_zero_flat_indices)}\\n\")\n",
        "            f.write(f\"Originally pruned weights that remained zero naturally: {len(still_pruned)}\\n\")\n",
        "\n",
        "            f.write(f\"Originally pruned weights that became non-zero (will be re-zeroed by mask): {len(no_longer_zero)}\\n\")\n",
        "            f.write(f\"Weights that became zero naturally during training: {len(naturally_zero)}\\n\")\n",
        "\n",
        "            # Also save the full list to a separate CSV file for easier processing\n",
        "            csv_path = os.path.join(self.output_dir, f\"pre-mask-zero-indices_batch-{batch_num}.csv\")\n",
        "            with open(csv_path, 'w', newline='') as csv_file:\n",
        "                writer = csv.writer(csv_file)\n",
        "                writer.writerow(['flat_index', 'is_originally_pruned'])  # Header\n",
        "                for idx in all_current_zero_flat_indices:\n",
        "                    is_pruned = 1 if idx in original_pruned_set else 0\n",
        "                    writer.writerow([idx, is_pruned])\n",
        "\n",
        "    def save_all_zero_indices(self, batch_num):\n",
        "        \"\"\"Save all indices that are currently zero to a separate file\"\"\"\n",
        "        # Dictionary to store which indices are currently zero\n",
        "        current_zero_indices_per_layer = {}\n",
        "        all_current_zero_flat_indices = []\n",
        "\n",
        "        # Track total parameters for flat index calculation\n",
        "        params_so_far = 0\n",
        "\n",
        "        # Check each layer for zero weights\n",
        "        for i, layer_idx in enumerate(self.layer_indices):\n",
        "            layer = self.model.layers[layer_idx]\n",
        "            weights = layer.get_weights()[0]\n",
        "            flat_weights = weights.flatten()\n",
        "\n",
        "            # Find all indices that are zero\n",
        "            zero_indices = np.where(flat_weights == 0)[0]\n",
        "            current_zero_indices_per_layer[i] = sorted(zero_indices.tolist())\n",
        "\n",
        "            # Convert to flat indices across the entire model\n",
        "            flat_zero_indices = [idx + params_so_far for idx in zero_indices]\n",
        "            all_current_zero_flat_indices.extend(flat_zero_indices)\n",
        "\n",
        "            params_so_far += flat_weights.size\n",
        "\n",
        "        all_current_zero_flat_indices = sorted(all_current_zero_flat_indices)\n",
        "\n",
        "        # Write all zero indices to a separate file\n",
        "        with open(os.path.join(self.output_dir, f\"all-zero-indices_batch-{batch_num}.txt\"), 'w') as f:\n",
        "            f.write(f\"Batch {batch_num} - All Zero Weight Indices\\n\")\n",
        "            f.write(f\"===================================\\n\\n\")\n",
        "\n",
        "            # Write summary statistics\n",
        "            total_zero_indices = len(all_current_zero_flat_indices)\n",
        "            f.write(f\"Total zero weights: {total_zero_indices}\\n\\n\")\n",
        "\n",
        "            # Write zero indices per layer\n",
        "            f.write(\"Zero indices per layer:\\n\")\n",
        "            for layer_idx, indices in current_zero_indices_per_layer.items():\n",
        "                f.write(f\"Layer index {layer_idx}: {len(indices)} zero indices\\n\")\n",
        "\n",
        "                # For small numbers of indices, write them all\n",
        "                if len(indices) <= 20:\n",
        "                    f.write(f\"  {indices}\\n\")\n",
        "                else:\n",
        "                    # For larger sets, write first and last 10\n",
        "                    f.write(f\"  First 10: {indices[:10]}\\n\")\n",
        "                    f.write(f\"  Last 10: {indices[-10:]}\\n\")\n",
        "\n",
        "            # Write all flat indices (not just the first 100)\n",
        "            f.write(\"\\nAll zero flat indices:\\n\")\n",
        "            f.write(f\"{all_current_zero_flat_indices}\\n\")\n",
        "\n",
        "            # Additional statistics\n",
        "            orig_pruned_count = len(self.all_pruned_flat_indices)\n",
        "            new_zero_count = total_zero_indices - orig_pruned_count\n",
        "\n",
        "            f.write(f\"\\nSummary statistics:\\n\")\n",
        "            f.write(f\"Originally pruned weights: {orig_pruned_count}\\n\")\n",
        "            f.write(f\"Total zero weights: {total_zero_indices}\\n\")\n",
        "            f.write(f\"Additional zero weights (from training): {new_zero_count if new_zero_count > 0 else 0}\\n\")\n",
        "\n",
        "            # Also save the full list to a separate CSV file for easier processing\n",
        "            csv_path = os.path.join(self.output_dir, f\"all-zero-indices_batch-{batch_num}.csv\")\n",
        "            with open(csv_path, 'w', newline='') as csv_file:\n",
        "                writer = csv.writer(csv_file)\n",
        "                writer.writerow(['flat_index'])  # Header\n",
        "                for idx in all_current_zero_flat_indices:\n",
        "                    writer.writerow([idx])\n",
        "# Enhanced Parameter Mask Pruning function with verification\n",
        "def parameter_mask_pruning(model, prune_percentage, seed=None, output_dir=\"pruning_verification\"):\n",
        "    \"\"\"\n",
        "    Randomly select a percentage of weights across the entire network and set them to zero.\n",
        "    Added functionality to save pruned indices to files for verification.\n",
        "\n",
        "    Parameters:\n",
        "    model -- The Keras model to prune\n",
        "    prune_percentage -- Percentage of weights to prune (0-100)\n",
        "    seed -- Random seed for reproducibility\n",
        "    output_dir -- Directory to save verification files\n",
        "\n",
        "    Returns:\n",
        "    The pruned model with a custom weight mask\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Set random seed if provided\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    # Get all trainable weights in the model\n",
        "    all_weights = []\n",
        "    all_shapes = []\n",
        "    all_layer_indices = []\n",
        "    layer_info = []  # Store layer name and shape for reference\n",
        "\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        if isinstance(layer, (Conv2D, Dense)) and len(layer.weights) > 0:\n",
        "            # Only consider weight matrices, not biases\n",
        "            weight = layer.get_weights()[0]\n",
        "            all_weights.append(weight)\n",
        "            all_shapes.append(weight.shape)\n",
        "            all_layer_indices.append(i)\n",
        "            layer_info.append(f\"Layer {i} ({layer.name}): {weight.shape}\")\n",
        "\n",
        "    # Count total parameters\n",
        "    total_params = sum(w.size for w in all_weights)\n",
        "\n",
        "    # For tiny test, if percentage is close to 0.00013514851% (which would prune exactly 10 parameters in a 7,399,616 parameter model)\n",
        "    # Exact percentage to prune 10 parameters out of 7,399,616: 0.00013514851%\n",
        "    if prune_percentage < 0.0002:  # Using a threshold slightly higher than the exact percentage\n",
        "        num_to_prune = 10\n",
        "        print(f\"Test mode: Pruning exactly 10 parameters (approx. {prune_percentage:.10f}% of {total_params:,} parameters)\")\n",
        "    else:\n",
        "        num_to_prune = int(total_params * prune_percentage / 100)\n",
        "        print(f\"Pruning {num_to_prune:,} parameters ({prune_percentage:.2f}% of {total_params:,} parameters)\")\n",
        "\n",
        "    print(f\"Total trainable parameters: {total_params:,}\")\n",
        "    print(f\"Parameters to prune: {num_to_prune:,} ({prune_percentage}%)\")\n",
        "\n",
        "    # Create masks for each layer (initially all ones)\n",
        "    masks = [np.ones_like(w) for w in all_weights]\n",
        "\n",
        "    # Dictionary to track which indices were set to zero in each layer\n",
        "    pruned_indices_per_layer = {}\n",
        "\n",
        "    # Store flat indices for verification\n",
        "    all_pruned_flat_indices = []\n",
        "\n",
        "    # If pruning percentage is not 0, create masks and apply them\n",
        "    if prune_percentage > 0:\n",
        "        # Randomly select indices to prune across all parameters\n",
        "        flat_indices = np.random.choice(total_params, size=num_to_prune, replace=False)\n",
        "        all_pruned_flat_indices = sorted(flat_indices.tolist())\n",
        "\n",
        "        # Map flat indices back to layer, row, col indices\n",
        "        params_so_far = 0\n",
        "        for i, weight in enumerate(all_weights):\n",
        "            size = weight.size\n",
        "            # Get indices that fall within this layer\n",
        "            indices_in_layer = flat_indices[(flat_indices >= params_so_far) &\n",
        "                                          (flat_indices < params_so_far + size)] - params_so_far\n",
        "\n",
        "            # Store these indices for verification\n",
        "            pruned_indices_per_layer[i] = sorted(indices_in_layer.tolist())\n",
        "\n",
        "            # Flatten the mask, set the selected indices to zero, then reshape back\n",
        "            flat_mask = masks[i].flatten()\n",
        "            flat_mask[indices_in_layer] = 0\n",
        "            masks[i] = flat_mask.reshape(all_shapes[i])\n",
        "\n",
        "            params_so_far += size\n",
        "\n",
        "        # Apply masks to each layer's weights\n",
        "        for i, layer_idx in enumerate(all_layer_indices):\n",
        "            layer = model.layers[layer_idx]\n",
        "            weights = layer.get_weights()\n",
        "            weights[0] = weights[0] * masks[i]  # Apply mask to weights\n",
        "            layer.set_weights(weights)\n",
        "\n",
        "    # Write pruned indices to file\n",
        "    with open(os.path.join(output_dir, \"prune-indices_batch-0.txt\"), 'w') as f:\n",
        "        f.write(f\"Total parameters: {total_params}\\n\")\n",
        "        f.write(f\"Total pruned: {num_to_prune}\\n\\n\")\n",
        "        f.write(\"Layer information:\\n\")\n",
        "        for info in layer_info:\n",
        "            f.write(f\"{info}\\n\")\n",
        "        f.write(\"\\nPruned indices per layer:\\n\")\n",
        "        for layer_idx, indices in pruned_indices_per_layer.items():\n",
        "            f.write(f\"Layer index {layer_idx}: {len(indices)} pruned indices\\n\")\n",
        "            if len(indices) <= 20:  # Only print all indices if there are few\n",
        "                f.write(f\"  {indices}\\n\")\n",
        "            else:\n",
        "                f.write(f\"  First 10: {indices[:10]}\\n\")\n",
        "                f.write(f\"  Last 10: {indices[-10:]}\\n\")\n",
        "\n",
        "        f.write(\"\\nAll pruned flat indices:\\n\")\n",
        "        # Print all pruned indices, not just first/last 10\n",
        "        f.write(f\"{all_pruned_flat_indices}\\n\")\n",
        "\n",
        "        # Also save the full list to a separate CSV file for easier processing\n",
        "        csv_path = os.path.join(output_dir, \"pruned_indices.csv\")\n",
        "        with open(csv_path, 'w', newline='') as csv_file:\n",
        "            writer = csv.writer(csv_file)\n",
        "            writer.writerow(['flat_index'])  # Header\n",
        "            for idx in all_pruned_flat_indices:\n",
        "                writer.writerow([idx])\n",
        "\n",
        "    # Attach the mask callback to the model for later use\n",
        "    mask_callback = MaskWeightsCallback(\n",
        "        masks,\n",
        "        all_layer_indices,\n",
        "        pruned_indices_per_layer,\n",
        "        all_pruned_flat_indices,\n",
        "        output_dir\n",
        "    )\n",
        "\n",
        "    model.mask_callback = mask_callback\n",
        "\n",
        "    # Reset random seed\n",
        "    if seed is not None:\n",
        "        np.random.seed(None)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Simple logger class for training metrics\n",
        "class SimpleLogger(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, test_data, batch_size, ce_threshold=None, baseline_ce=None, output_dir=None):\n",
        "        \"\"\"\n",
        "        Initialize the Simple Logger\n",
        "\n",
        "        Parameters:\n",
        "        test_data -- tuple of (x_test, y_test)\n",
        "        batch_size -- batch size for evaluation\n",
        "        ce_threshold -- Threshold for CE (ln(10) or ln(100) depending on dataset)\n",
        "        baseline_ce -- baseline cross-entropy from unpruned model\n",
        "        output_dir -- directory to save logs\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.test_x, self.test_y = test_data\n",
        "        self.batch_size = batch_size\n",
        "        self.total_batches = 0  # Using total_batches for continuous numbering across epochs\n",
        "        self.epoch = 0\n",
        "        self.baseline_ce = baseline_ce\n",
        "        self.ce_threshold = ce_threshold  # Store the CE threshold (ln(10) or ln(100))\n",
        "        self.ipa_start_batch = None  # Track when CE first goes below threshold\n",
        "        self.output_dir = output_dir\n",
        "\n",
        "        # Create log file\n",
        "        if output_dir:\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "            self.log_file = os.path.join(output_dir, \"training_log.csv\")\n",
        "            with open(self.log_file, 'w') as f:\n",
        "                f.write(\"Epoch,Batch,Train_Accuracy,Train_CE,Test_Accuracy,Test_CE,CE_Diff,IPA\\n\")\n",
        "        else:\n",
        "            self.log_file = None\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        # If baseline CE is not provided, calculate it\n",
        "        if self.baseline_ce is None:\n",
        "            print(\"Calculating baseline CE...\")\n",
        "            _, _, self.baseline_ce = self.model.evaluate(\n",
        "                self.test_x, self.test_y,\n",
        "                batch_size=self.batch_size,\n",
        "                verbose=1\n",
        "            )\n",
        "            print(f\"Baseline CE (CEo): {self.baseline_ce}\")\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch = epoch + 1\n",
        "        # No batch number reset - using total_batches for continuous counting\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        self.total_batches += 1\n",
        "\n",
        "        # Calculate metrics on test data (silently)\n",
        "        _, test_acc, test_ce = self.model.evaluate(\n",
        "            self.test_x, self.test_y,\n",
        "            batch_size=self.batch_size,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Calculate CE difference\n",
        "        ce_diff = abs(test_ce - self.baseline_ce)\n",
        "\n",
        "        # Check if CE is below threshold and update ipa_start_batch if first time\n",
        "        if self.ce_threshold is not None and self.ipa_start_batch is None and test_ce <= self.ce_threshold:\n",
        "            self.ipa_start_batch = self.total_batches\n",
        "            print(f\"CE dropped below threshold ({self.ce_threshold:.4f}) at batch {self.ipa_start_batch} (CE = {test_ce:.4f})\")\n",
        "\n",
        "        # Calculate IPA\n",
        "        # If CE is above threshold, IPA is None\n",
        "        # Otherwise, use the current batch number (not adjusted)\n",
        "        if self.ce_threshold is not None and test_ce <= self.ce_threshold:\n",
        "            ipa = ce_diff / (BATCH_SIZE_TRAIN * self.total_batches) if self.total_batches > 0 else 0\n",
        "            ipa_value = ipa\n",
        "        else:\n",
        "            ipa_value = \"N/A\"\n",
        "\n",
        "        # Log to file if available\n",
        "        if self.log_file:\n",
        "            with open(self.log_file, 'a') as f:\n",
        "                f.write(f\"{self.epoch},{self.total_batches},{logs.get('accuracy', 0)},{logs.get('loss', 0)},{test_acc},{test_ce},{ce_diff},{ipa_value}\\n\")\n",
        "\n",
        "        # Print progress\n",
        "        if self.total_batches % 10 == 0:\n",
        "            print(f\"Batch {self.total_batches}: Train Acc={logs.get('accuracy', 0):.4f}, Test Acc={test_acc:.4f}, Test CE={test_ce:.4f}\")\n",
        "\n",
        "    def get_final_metrics(self):\n",
        "        \"\"\"Return the final IPA and test accuracy\"\"\"\n",
        "        # Calculate final metrics\n",
        "        _, test_acc, test_ce = self.model.evaluate(\n",
        "            self.test_x, self.test_y,\n",
        "            batch_size=self.batch_size,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        ce_diff = abs(test_ce - self.baseline_ce)\n",
        "\n",
        "        # Check if CE is below threshold\n",
        "        if self.ce_threshold is not None and test_ce <= self.ce_threshold:\n",
        "            ipa = ce_diff / (BATCH_SIZE_TRAIN * self.total_batches) if self.total_batches > 0 else 0\n",
        "            return {\n",
        "                'Final Test Accuracy': test_acc,\n",
        "                'IPA': ipa * 1000,  # Scale by 1000\n",
        "                'CE Below Threshold': True\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'Final Test Accuracy': test_acc,\n",
        "                'IPA': 0,  # IPA is 0 if CE is above threshold\n",
        "                'CE Below Threshold': False\n",
        "            }\n",
        "\n",
        "# Function to run a single experiment with a specific pruning percentage and seed\n",
        "def run_single_experiment(dataset_name, pruning_method, prune_percentage, run_number, baseline_ce,\n",
        "                         x_train, y_train, x_test, y_test, num_classes, output_dir=\"pruning_verification\"):\n",
        "    \"\"\"\n",
        "    Run a single experiment with a specific pruning percentage and seed.\n",
        "\n",
        "    Parameters:\n",
        "    dataset_name -- Name of the dataset\n",
        "    pruning_method -- Pruning method to use\n",
        "    prune_percentage -- Percentage to prune\n",
        "    run_number -- Run number (for setting seed)\n",
        "    baseline_ce -- Baseline cross-entropy\n",
        "    x_train, y_train, x_test, y_test -- Training and test data\n",
        "    num_classes -- Number of classes\n",
        "    output_dir -- Directory to save verification files\n",
        "\n",
        "    Returns:\n",
        "    Dictionary with results\n",
        "    \"\"\"\n",
        "    # Get directory path (either on Google Drive or locally)\n",
        "    verification_dir = get_output_dir(os.path.join(output_dir, f\"P{prune_percentage}_run{run_number}\"))\n",
        "\n",
        "    print(f\"\\nRunning experiment: {dataset_name}, {pruning_method}, P% = {prune_percentage}, Run #{run_number}\")\n",
        "    print(f\"Verification files will be saved to: {verification_dir}\")\n",
        "\n",
        "    # Use run number as seed for reproducibility\n",
        "    seed = 42 + run_number\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Define CE threshold based on dataset\n",
        "    if dataset_name == 'cifar100':\n",
        "        ce_threshold = math.log(100)  # ln(100) for CIFAR-100\n",
        "        print(f\"Using CE threshold ln(100) = {ce_threshold:.4f} for CIFAR-100\")\n",
        "    else:\n",
        "        ce_threshold = math.log(10)  # ln(10) for other datasets\n",
        "        print(f\"Using CE threshold ln(10) = {ce_threshold:.4f} for {dataset_name}\")\n",
        "\n",
        "    # Create model\n",
        "    model = create_densenet121(input_shape=x_train.shape[1:], num_classes=num_classes)\n",
        "\n",
        "    # Apply parameter mask pruning with seed\n",
        "    model = parameter_mask_pruning(model, prune_percentage, seed=seed, output_dir=verification_dir)\n",
        "\n",
        "    # Store the mask callback for use during training\n",
        "    mask_callback = model.mask_callback\n",
        "\n",
        "    # Compile model\n",
        "    # Compile model\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', 'categorical_crossentropy']\n",
        "    )\n",
        "\n",
        "    # Setup logger\n",
        "    simple_logger = SimpleLogger(\n",
        "        test_data=(x_test, y_test),\n",
        "        batch_size=BATCH_SIZE_TEST,\n",
        "        ce_threshold=ce_threshold,\n",
        "        baseline_ce=baseline_ce,\n",
        "        output_dir=verification_dir\n",
        "    )\n",
        "\n",
        "    # Setup callbacks\n",
        "    callbacks = [simple_logger, mask_callback]\n",
        "\n",
        "    # Train for specified number of epochs\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=BATCH_SIZE_TRAIN,\n",
        "        validation_batch_size=BATCH_SIZE_TEST,\n",
        "        epochs=EPOCHS_PER_RUN,\n",
        "        validation_data=(x_test, y_test),\n",
        "        callbacks=callbacks,\n",
        "        verbose=0  # Less verbose output\n",
        "    )\n",
        "\n",
        "    # Get final metrics\n",
        "    final_metrics = simple_logger.get_final_metrics()\n",
        "\n",
        "    # Clear memory\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # Create a report file to summarize verification results\n",
        "    with open(os.path.join(verification_dir, \"verification_summary.txt\"), 'w') as f:\n",
        "        f.write(f\"Pruning Verification Summary\\n\")\n",
        "        f.write(f\"==========================\\n\")\n",
        "        f.write(f\"Dataset: {dataset_name}\\n\")\n",
        "        f.write(f\"Pruning Method: {pruning_method}\\n\")\n",
        "        f.write(f\"Pruning Percentage: {prune_percentage}%\\n\")\n",
        "        f.write(f\"Run Number: {run_number}\\n\\n\")\n",
        "\n",
        "        # Compare files using diff-like approach\n",
        "        f.write(\"Verification Results:\\n\")\n",
        "        try:\n",
        "            with open(os.path.join(verification_dir, \"prune-indices_batch-0.txt\"), 'r') as f0, \\\n",
        "                 open(os.path.join(verification_dir, \"prune-indices_batch-1.txt\"), 'r') as f1, \\\n",
        "                 open(os.path.join(verification_dir, \"prune-indices_batch-2.txt\"), 'r') as f2, \\\n",
        "                 open(os.path.join(verification_dir, \"prune-indices_batch-3.txt\"), 'r') as f3:\n",
        "\n",
        "                batch0 = f0.read()\n",
        "                batch1 = f1.read()\n",
        "                batch2 = f2.read()\n",
        "                batch3 = f3.read()\n",
        "\n",
        "                if \"All pruned indices are still zero\" in batch1 and \\\n",
        "                   \"All pruned indices are still zero\" in batch2 and \\\n",
        "                   \"All pruned indices are still zero\" in batch3:\n",
        "                    f.write(\"VERIFICATION SUCCESSFUL: All pruned indices remained zero across all batches.\\n\")\n",
        "                    print(\"VERIFICATION SUCCESSFUL: All pruned indices remained zero across all batches.\")\n",
        "                else:\n",
        "                    if \"All pruned indices are still zero\" not in batch1:\n",
        "                        f.write(\"VERIFICATION FAILED: Some pruned indices did not remain zero in batch 1.\\n\")\n",
        "                    if \"All pruned indices are still zero\" not in batch2:\n",
        "                        f.write(\"VERIFICATION FAILED: Some pruned indices did not remain zero in batch 2.\\n\")\n",
        "                    if \"All pruned indices are still zero\" not in batch3:\n",
        "                        f.write(\"VERIFICATION FAILED: Some pruned indices did not remain zero in batch 3.\\n\")\n",
        "                    print(\"VERIFICATION FAILED: Some pruned indices did not remain zero. Check log files.\")\n",
        "        except Exception as e:\n",
        "            f.write(f\"Error during verification: {str(e)}\\n\")\n",
        "            print(f\"Error during verification: {str(e)}\")\n",
        "\n",
        "        # Add analysis of all zero indices\n",
        "        f.write(\"\\nAnalysis of All Zero Weights:\\n\")\n",
        "        try:\n",
        "            zero_counts = {}\n",
        "            for batch in [0, 1, 2, 3]:\n",
        "                zero_file = os.path.join(verification_dir, f\"all-zero-indices_batch-{batch}.txt\")\n",
        "                if os.path.exists(zero_file):\n",
        "                    with open(zero_file, 'r') as zf:\n",
        "                        for line in zf:\n",
        "                            if \"Total zero weights:\" in line:\n",
        "                                count = int(line.split(\":\")[1].strip())\n",
        "                                zero_counts[batch] = count\n",
        "                                f.write(f\"  Batch {batch}: {count} zero weights\\n\")\n",
        "                                break\n",
        "\n",
        "            # Calculate changes between batches\n",
        "            if len(zero_counts) > 1:\n",
        "                f.write(\"\\nChanges in zero weights between batches:\\n\")\n",
        "                batches = sorted(zero_counts.keys())\n",
        "                for i in range(len(batches)-1):\n",
        "                    curr_batch = batches[i]\n",
        "                    next_batch = batches[i+1]\n",
        "                    diff = zero_counts[next_batch] - zero_counts[curr_batch]\n",
        "                    if diff > 0:\n",
        "                        f.write(f\"  Batch {curr_batch} → {next_batch}: +{diff} weights became zero\\n\")\n",
        "                    elif diff < 0:\n",
        "                        f.write(f\"  Batch {curr_batch} → {next_batch}: {diff} zero weights became non-zero (unexpected!)\\n\")\n",
        "                    else:\n",
        "                        f.write(f\"  Batch {curr_batch} → {next_batch}: No change in zero weights\\n\")\n",
        "        except Exception as e:\n",
        "            f.write(f\"Error analyzing zero weights: {str(e)}\\n\")\n",
        "\n",
        "    result = {\n",
        "        'Pruning Percentage': prune_percentage,\n",
        "        'Run Number': run_number,\n",
        "        'Final Test Accuracy': final_metrics['Final Test Accuracy'],\n",
        "        'IPA': final_metrics['IPA'],\n",
        "        'CE Below Threshold': final_metrics['CE Below Threshold'],\n",
        "        'Verification': \"pending\"  # You can update this based on verification results\n",
        "    }\n",
        "\n",
        "    threshold_status = \"CE below threshold\" if final_metrics['CE Below Threshold'] else \"CE above threshold (IPA set to 0)\"\n",
        "    print(f\"P{prune_percentage} Run #{run_number} - Test Accuracy: {result['Final Test Accuracy']:.4f}, IPA × 1000: {result['IPA']:.6f}, {threshold_status}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "# Script to extract and compare pruned indices from files\n",
        "def compare_pruned_indices_files(dir_path, batch_numbers=[0, 1, 2, 3]):\n",
        "    \"\"\"\n",
        "    Extract pruned indices from batch files and compare them to verify pruning.\n",
        "\n",
        "    Parameters:\n",
        "    dir_path -- Directory containing the pruned indices files\n",
        "    batch_numbers -- List of batch numbers to compare\n",
        "\n",
        "    Returns:\n",
        "    Dictionary with comparison results\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    print(f\"\\nComparing pruned indices in {dir_path}\")\n",
        "\n",
        "    results = {\n",
        "        'all_matching': True,\n",
        "        'comparisons': [],\n",
        "        'zero_indices_analysis': {}\n",
        "    }\n",
        "\n",
        "    # Read the reference file (batch 0)\n",
        "    ref_path = os.path.join(dir_path, f\"prune-indices_batch-{batch_numbers[0]}.txt\")\n",
        "    if not os.path.exists(ref_path):\n",
        "        print(f\"Reference file {ref_path} not found!\")\n",
        "        return {'all_matching': False, 'error': f\"Reference file not found: {ref_path}\"}\n",
        "\n",
        "    with open(ref_path, 'r') as f:\n",
        "        ref_content = f.read()\n",
        "\n",
        "    # Extract pruned indices from reference file\n",
        "    pruned_lines = []\n",
        "    in_pruned_section = False\n",
        "    for line in ref_content.split('\\n'):\n",
        "        if 'Pruned indices per layer' in line:\n",
        "            in_pruned_section = True\n",
        "            continue\n",
        "        if in_pruned_section and 'All pruned flat indices' in line:\n",
        "            in_pruned_section = False\n",
        "        if in_pruned_section and 'Layer index' in line and 'pruned indices' in line:\n",
        "            pruned_lines.append(line)\n",
        "        if in_pruned_section and any(x in line for x in ['First 10', 'Last 10', '[']):\n",
        "            pruned_lines.append(line)\n",
        "\n",
        "    # Analyze all zero indices files\n",
        "    for batch in batch_numbers:\n",
        "        zero_path = os.path.join(dir_path, f\"all-zero-indices_batch-{batch}.txt\")\n",
        "        if os.path.exists(zero_path):\n",
        "            print(f\"Analyzing all zero indices for batch {batch}...\")\n",
        "\n",
        "            with open(zero_path, 'r') as f:\n",
        "                zero_content = f.read()\n",
        "\n",
        "            # Extract total zero indices\n",
        "            total_zeros_match = re.search(r\"Total zero weights: (\\d+)\", zero_content)\n",
        "            if total_zeros_match:\n",
        "                total_zeros = int(total_zeros_match.group(1))\n",
        "                results['zero_indices_analysis'][batch] = {\n",
        "                    'total_zero_weights': total_zeros\n",
        "                }\n",
        "                print(f\"  Batch {batch}: {total_zeros} total zero weights\")\n",
        "\n",
        "    # For each batch file, extract and compare with reference\n",
        "    for batch in batch_numbers[1:]:\n",
        "        batch_path = os.path.join(dir_path, f\"prune-indices_batch-{batch}.txt\")\n",
        "        if not os.path.exists(batch_path):\n",
        "            print(f\"Batch file {batch_path} not found!\")\n",
        "            results['all_matching'] = False\n",
        "            results['comparisons'].append({\n",
        "                'batch': batch,\n",
        "                'matching': False,\n",
        "                'error': f\"File not found: {batch_path}\"\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        with open(batch_path, 'r') as f:\n",
        "            batch_content = f.read()\n",
        "\n",
        "        # Check if the \"All pruned indices are still zero\" message is present\n",
        "        if \"All pruned indices are still zero\" in batch_content:\n",
        "            print(f\"Batch {batch}: All pruned indices are still zero - VERIFICATION PASSED\")\n",
        "            results['comparisons'].append({\n",
        "                'batch': batch,\n",
        "                'matching': True,\n",
        "                'message': \"All pruned indices are still zero\"\n",
        "            })\n",
        "        else:\n",
        "            # If the success message isn't found, check for error messages\n",
        "            error_lines = []\n",
        "            for line in batch_content.split('\\n'):\n",
        "                if 'ERROR:' in line:\n",
        "                    error_lines.append(line)\n",
        "\n",
        "            if error_lines:\n",
        "                print(f\"Batch {batch}: Verification FAILED - some pruned indices are no longer zero\")\n",
        "                for line in error_lines:\n",
        "                    print(f\"  {line}\")\n",
        "                results['all_matching'] = False\n",
        "                results['comparisons'].append({\n",
        "                    'batch': batch,\n",
        "                    'matching': False,\n",
        "                    'errors': error_lines\n",
        "                })\n",
        "            else:\n",
        "                print(f\"Batch {batch}: Inconclusive - no clear success or error messages\")\n",
        "                results['all_matching'] = False\n",
        "                results['comparisons'].append({\n",
        "                    'batch': batch,\n",
        "                    'matching': False,\n",
        "                    'message': \"Verification inconclusive\"\n",
        "                })\n",
        "\n",
        "    # Compare zero indices across batches\n",
        "    if len(results['zero_indices_analysis']) > 1:\n",
        "        print(\"\\nZero indices comparison across batches:\")\n",
        "        batches = sorted(results['zero_indices_analysis'].keys())\n",
        "        for i in range(len(batches)-1):\n",
        "            current = batches[i]\n",
        "            next_batch = batches[i+1]\n",
        "            current_zeros = results['zero_indices_analysis'][current]['total_zero_weights']\n",
        "            next_zeros = results['zero_indices_analysis'][next_batch]['total_zero_weights']\n",
        "            diff = next_zeros - current_zeros\n",
        "\n",
        "            if diff > 0:\n",
        "                print(f\"  Batch {current} → {next_batch}: +{diff} new zero weights\")\n",
        "            elif diff < 0:\n",
        "                print(f\"  Batch {current} → {next_batch}: {diff} fewer zero weights (unexpected!)\")\n",
        "            else:\n",
        "                print(f\"  Batch {current} → {next_batch}: No change in zero weights\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Additional utility to create Linux shell script for batch comparison\n",
        "def create_comparison_script(output_dir):\n",
        "    \"\"\"\n",
        "    Create a shell script to compare pruned indices files on Linux.\n",
        "\n",
        "    Parameters:\n",
        "    output_dir -- Directory where verification tests were run\n",
        "    \"\"\"\n",
        "    script_path = os.path.join(output_dir, \"compare_indices.sh\")\n",
        "\n",
        "    with open(script_path, 'w') as f:\n",
        "        f.write(\"#!/bin/bash\\n\\n\")\n",
        "        f.write(\"# Script to compare pruned indices files for DenseNet pruning verification\\n\\n\")\n",
        "\n",
        "        # Tiny pruning comparison\n",
        "        f.write(\"echo '===== Comparing Tiny Pruning (10 parameters) ====='\\n\")\n",
        "        f.write(\"cd tiny_pruning/P0.00013514851_run1\\n\")\n",
        "        f.write(\"echo 'Comparing batch 0 with batch 1:'\\n\")\n",
        "        f.write(\"diff -y prune-indices_batch-0.txt prune-indices_batch-1.txt | grep -v 'NOTE:' | grep 'ERROR\\\\|missing'\\n\")\n",
        "        f.write(\"echo 'Comparing batch 0 with batch 2:'\\n\")\n",
        "        f.write(\"diff -y prune-indices_batch-0.txt prune-indices_batch-2.txt | grep -v 'NOTE:' | grep 'ERROR\\\\|missing'\\n\")\n",
        "        f.write(\"echo 'Comparing batch 0 with batch 3:'\\n\")\n",
        "        f.write(\"diff -y prune-indices_batch-0.txt prune-indices_batch-3.txt | grep -v 'NOTE:' | grep 'ERROR\\\\|missing'\\n\")\n",
        "        f.write(\"cd ../..\\n\\n\")\n",
        "\n",
        "        # Medium pruning comparison\n",
        "        f.write(\"echo '===== Comparing Medium Pruning (30%) ====='\\n\")\n",
        "        f.write(\"cd medium_pruning/P30_run1\\n\")\n",
        "        f.write(\"echo 'Checking batch 1 verification result:'\\n\")\n",
        "        f.write(\"grep 'All pruned indices are still zero\\\\|ERROR' prune-indices_batch-1.txt\\n\")\n",
        "        f.write(\"echo 'Checking batch 2 verification result:'\\n\")\n",
        "        f.write(\"grep 'All pruned indices are still zero\\\\|ERROR' prune-indices_batch-2.txt\\n\")\n",
        "        f.write(\"echo 'Checking batch 3 verification result:'\\n\")\n",
        "        f.write(\"grep 'All pruned indices are still zero\\\\|ERROR' prune-indices_batch-3.txt\\n\")\n",
        "        f.write(\"cd ../..\\n\\n\")\n",
        "\n",
        "        # Add comparison of all zero weights files\n",
        "        f.write(\"echo '===== Analyzing All Zero Weights ====='\\n\")\n",
        "        f.write(\"echo 'Tiny Pruning - Zero Weight Counts:'\\n\")\n",
        "        f.write(\"cd tiny_pruning/P0.00013514851_run1\\n\")\n",
        "        f.write(\"echo 'Batch 0:'\\n\")\n",
        "        f.write(\"grep 'Total zero weights:' all-zero-indices_batch-0.txt\\n\")\n",
        "        f.write(\"echo 'Batch 1:'\\n\")\n",
        "        f.write(\"grep 'Total zero weights:' all-zero-indices_batch-1.txt\\n\")\n",
        "        f.write(\"echo 'Batch 2:'\\n\")\n",
        "        f.write(\"grep 'Total zero weights:' all-zero-indices_batch-2.txt\\n\")\n",
        "        f.write(\"echo 'Batch 3:'\\n\")\n",
        "        f.write(\"grep 'Total zero weights:' all-zero-indices_batch-3.txt\\n\")\n",
        "        f.write(\"cd ../..\\n\\n\")\n",
        "\n",
        "        f.write(\"echo 'Medium Pruning - Zero Weight Counts:'\\n\")\n",
        "        f.write(\"cd medium_pruning/P30_run1\\n\")\n",
        "        f.write(\"echo 'Batch 0:'\\n\")\n",
        "        f.write(\"grep 'Total zero weights:' all-zero-indices_batch-0.txt\\n\")\n",
        "        f.write(\"echo 'Batch 1:'\\n\")\n",
        "        f.write(\"grep 'Total zero weights:' all-zero-indices_batch-1.txt\\n\")\n",
        "        f.write(\"echo 'Batch 2:'\\n\")\n",
        "        f.write(\"grep 'Total zero weights:' all-zero-indices_batch-2.txt\\n\")\n",
        "        f.write(\"echo 'Batch 3:'\\n\")\n",
        "        f.write(\"grep 'Total zero weights:' all-zero-indices_batch-3.txt\\n\")\n",
        "        f.write(\"cd ../..\\n\")\n",
        "\n",
        "    # Make the script executable\n",
        "    os.chmod(script_path, 0o755)\n",
        "\n",
        "    print(f\"Created comparison shell script: {script_path}\")\n",
        "    if GOOGLE_DRIVE_MOUNTED:\n",
        "        print(\"This script is available in your Google Drive for download and use on a Linux machine.\")\n",
        "    else:\n",
        "        print(\"Upload this script along with the verification directories to a Linux machine\")\n",
        "        print(\"and run it to quickly check if pruning is working correctly.\")\n",
        "\n",
        "# Function to run the pruning verification tests\n",
        "def run_pruning_verification():\n",
        "    \"\"\"Run focused tests to verify that pruning is working correctly\"\"\"\n",
        "    print(\"Running DenseNet-121 pruning verification tests\")\n",
        "\n",
        "    # Create output directory\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir_name = f\"pruning_verification_{timestamp}\"\n",
        "    output_dir = get_output_dir(output_dir_name)\n",
        "\n",
        "    print(f\"Creating base output directory: {output_dir}\")\n",
        "\n",
        "    # Create subdirectories for tiny and medium pruning\n",
        "    tiny_pruning_dir = get_output_dir(os.path.join(output_dir_name, \"tiny_pruning\"))\n",
        "    medium_pruning_dir = get_output_dir(os.path.join(output_dir_name, \"medium_pruning\"))\n",
        "\n",
        "    # Load a dataset (using MNIST for quick testing)\n",
        "    dataset_name = 'mnist'\n",
        "    print(f\"\\nLoading {dataset_name} dataset for verification...\")\n",
        "    (x_train, y_train), (x_test, y_test), num_classes = load_dataset(dataset_name)\n",
        "\n",
        "    # Reduce dataset size for faster testing\n",
        "    x_train = x_train[:1000]\n",
        "    y_train = y_train[:1000]\n",
        "    x_test = x_test[:100]\n",
        "    y_test = y_test[:100]\n",
        "\n",
        "    # Create baseline model once\n",
        "    print(\"\\nCreating baseline model to calculate baseline CE...\")\n",
        "    baseline_model = create_densenet121(input_shape=x_train.shape[1:], num_classes=num_classes)\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
        "    baseline_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', 'categorical_crossentropy']\n",
        "    )\n",
        "    _, _, baseline_ce = baseline_model.evaluate(x_test, y_test, batch_size=BATCH_SIZE_TEST, verbose=1)\n",
        "    print(f\"Baseline CE (CEo): {baseline_ce}\")\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # Test 1: Tiny pruning (exactly 10 parameters)\n",
        "    print(\"\\n===== TEST 1: Tiny pruning (exactly 10 parameters) =====\")\n",
        "    run_single_experiment(\n",
        "        dataset_name=dataset_name,\n",
        "        pruning_method='parameter_mask',\n",
        "        prune_percentage=0.00013514851,  # Exact percentage to prune 10 parameters out of 7,399,616\n",
        "        run_number=1,\n",
        "        baseline_ce=baseline_ce,\n",
        "        x_train=x_train,\n",
        "        y_train=y_train,\n",
        "        x_test=x_test,\n",
        "        y_test=y_test,\n",
        "        num_classes=num_classes,\n",
        "        output_dir=tiny_pruning_dir\n",
        "    )\n",
        "\n",
        "    # Test 2: Medium pruning (30%)\n",
        "    print(\"\\n===== TEST 2: Medium pruning (30%) =====\")\n",
        "    run_single_experiment(\n",
        "        dataset_name=dataset_name,\n",
        "        pruning_method='parameter_mask',\n",
        "        prune_percentage=30,\n",
        "        run_number=1,\n",
        "        baseline_ce=baseline_ce,\n",
        "        x_train=x_train,\n",
        "        y_train=y_train,\n",
        "        x_test=x_test,\n",
        "        y_test=y_test,\n",
        "        num_classes=num_classes,\n",
        "        output_dir=medium_pruning_dir\n",
        "    )\n",
        "\n",
        "    # Create a summary of verification results\n",
        "    with open(os.path.join(output_dir, \"verification_summary.txt\"), 'w') as f:\n",
        "        f.write(\"DenseNet-121 Pruning Verification Summary\\n\")\n",
        "        f.write(\"=======================================\\n\\n\")\n",
        "        f.write(\"Two pruning tests were conducted:\\n\")\n",
        "        f.write(\"1. Tiny pruning: exactly 10 parameters pruned (0.00013514851% of 7,399,616 total parameters)\\n\")\n",
        "        f.write(\"2. Medium pruning: 30% of parameters pruned\\n\\n\")\n",
        "        f.write(\"For each test, pruned indices were tracked across batches 0 (initial), 1, 2, and 3.\\n\")\n",
        "        f.write(\"See the subdirectories for detailed verification results.\\n\\n\")\n",
        "        f.write(\"Instructions for comparing files with Linux 'diff' command:\\n\")\n",
        "        f.write(\"cd tiny_pruning/P0.00013514851_run1\\n\")\n",
        "        f.write(\"diff -y prune-indices_batch-0.txt prune-indices_batch-1.txt | grep -v 'NOTE:'\\n\")\n",
        "        f.write(\"diff -y prune-indices_batch-0.txt prune-indices_batch-2.txt | grep -v 'NOTE:'\\n\")\n",
        "        f.write(\"diff -y prune-indices_batch-0.txt prune-indices_batch-3.txt | grep -v 'NOTE:'\\n\\n\")\n",
        "        f.write(\"cd ../../medium_pruning/P30_run1\\n\")\n",
        "        f.write(\"diff prune-indices_batch-0.txt prune-indices_batch-1.txt | grep -v 'NOTE:'\\n\")\n",
        "        f.write(\"diff prune-indices_batch-0.txt prune-indices_batch-2.txt | grep -v 'NOTE:'\\n\")\n",
        "        f.write(\"diff prune-indices_batch-0.txt prune-indices_batch-3.txt | grep -v 'NOTE:'\\n\\n\")\n",
        "\n",
        "        f.write(\"To analyze ALL zero weights (not just pruned ones):\\n\")\n",
        "        f.write(\"cd tiny_pruning/P0.00013514851_run1\\n\")\n",
        "        f.write(\"grep 'Total zero weights:' all-zero-indices_batch-*.txt\\n\")\n",
        "        f.write(\"cd ../../medium_pruning/P30_run1\\n\")\n",
        "        f.write(\"grep 'Total zero weights:' all-zero-indices_batch-*.txt\\n\")\n",
        "\n",
        "    print(f\"\\nVerification tests complete! Results saved to {output_dir}\")\n",
        "    if GOOGLE_DRIVE_MOUNTED:\n",
        "        print(f\"Results are available in your Google Drive at: {GOOGLE_DRIVE_BASE_PATH}\")\n",
        "    print(\"Check the verification summary and individual test directories for detailed results.\")\n",
        "\n",
        "    # Create comparison script\n",
        "    create_comparison_script(output_dir)\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "# Function to find verification files in the filesystem\n",
        "def find_verification_files():\n",
        "    \"\"\"Utility to find verification files if they're not where expected\"\"\"\n",
        "    print(\"\\nSearching for verification files...\")\n",
        "\n",
        "    # List of patterns to look for\n",
        "    patterns = ['prune-indices_batch', 'all-zero-indices_batch', 'pruned_indices.csv']\n",
        "    found_files = []\n",
        "\n",
        "    if GOOGLE_DRIVE_MOUNTED:\n",
        "        # Search Google Drive\n",
        "        search_root = '/content/drive/My Drive'\n",
        "        print(f\"Searching in Google Drive: {search_root}\")\n",
        "\n",
        "        try:\n",
        "            for root, dirs, files in os.walk(search_root):\n",
        "                for file in files:\n",
        "                    if any(pattern in file for pattern in patterns):\n",
        "                        found_files.append(os.path.join(root, file))\n",
        "                        # Limit search to avoid taking too long\n",
        "                        if len(found_files) > 100:\n",
        "                            break\n",
        "                if len(found_files) > 100:\n",
        "                    break\n",
        "        except Exception as e:\n",
        "            print(f\"Error searching Google Drive: {str(e)}\")\n",
        "\n",
        "    # Also search locally\n",
        "    local_search_root = '.'\n",
        "    print(f\"Searching locally: {local_search_root}\")\n",
        "\n",
        "    for root, dirs, files in os.walk(local_search_root):\n",
        "        for file in files:\n",
        "            if any(pattern in file for pattern in patterns):\n",
        "                found_files.append(os.path.join(root, file))\n",
        "                # Limit search to avoid taking too long\n",
        "                if len(found_files) > 100:\n",
        "                    break\n",
        "        if len(found_files) > 100:\n",
        "            break\n",
        "\n",
        "    # Report findings\n",
        "    if found_files:\n",
        "        print(f\"Found {len(found_files)} verification-related files.\")\n",
        "        print(\"First 10 files found:\")\n",
        "        for i, file in enumerate(found_files[:10]):\n",
        "            print(f\"  {i+1}. {file}\")\n",
        "        if len(found_files) > 10:\n",
        "            print(f\"  ... and {len(found_files) - 10} more files.\")\n",
        "    else:\n",
        "        print(\"No verification files found.\")\n",
        "\n",
        "    return found_files\n",
        "\n",
        "# A more comprehensive verification function that both runs the tests and analyzes results\n",
        "def verify_densenet_pruning_comprehensive():\n",
        "    \"\"\"\n",
        "    Run the pruning verification tests and analyze the results\n",
        "    \"\"\"\n",
        "    # Run the verification tests\n",
        "    output_dir = run_pruning_verification()\n",
        "\n",
        "    # Fix for \"pruning is working correctly\" warning - we see the warning but the mask\n",
        "    # callback is re-applying the zeros, so the pruning is actually working\n",
        "    print(\"\\n===== NOTE ABOUT WARNINGS =====\")\n",
        "    print(\"You may see warnings about 'pruned weights became non-zero'. This is normal and expected.\")\n",
        "    print(\"These warnings indicate that gradient updates tried to change pruned weights,\")\n",
        "    print(\"but our MaskWeightsCallback detected this and re-applied the mask to set them back to zero.\")\n",
        "    print(\"The verification files will confirm that all pruned weights remained zero after the callback ran.\\n\")\n",
        "\n",
        "    # Run the comparison analysis\n",
        "    tiny_pruning_dir = os.path.join(output_dir, \"tiny_pruning\", \"P0.00013514851_run1\")\n",
        "    medium_pruning_dir = os.path.join(output_dir, \"medium_pruning\", \"P30_run1\")\n",
        "\n",
        "    tiny_results = compare_pruned_indices_files(tiny_pruning_dir)\n",
        "    # medium_results = compare_pruned_indices_files(medium_pruning_dir)\n",
        "\n",
        "    # Create a final verification report\n",
        "    report_path = os.path.join(output_dir, \"pruning_verification_report.txt\")\n",
        "    with open(report_path, 'w') as f:\n",
        "        f.write(\"DenseNet Pruning Verification Report\\n\")\n",
        "        f.write(\"==================================\\n\\n\")\n",
        "\n",
        "        f.write(\"TINY PRUNING TEST (10 parameters, 0.00013514851% of 7,399,616 total parameters)\\n\")\n",
        "        f.write(\"------------------------------------------------------\\n\")\n",
        "        if tiny_results['all_matching']:\n",
        "            f.write(\"PASS: All pruned indices remain zero across all batch updates\\n\")\n",
        "        else:\n",
        "            f.write(\"FAIL: Some pruned indices changed during training\\n\")\n",
        "            for comp in tiny_results.get('comparisons', []):\n",
        "                if not comp.get('matching', False):\n",
        "                    f.write(f\"  Batch {comp.get('batch')}: Verification failed\\n\")\n",
        "                    for error in comp.get('errors', []):\n",
        "                        f.write(f\"    {error}\\n\")\n",
        "\n",
        "        # Add analysis of zero indices across batches for tiny pruning\n",
        "        if 'zero_indices_analysis' in tiny_results and len(tiny_results['zero_indices_analysis']) > 0:\n",
        "            f.write(\"\\nAnalysis of ALL zero weights across batches:\\n\")\n",
        "            for batch, data in sorted(tiny_results['zero_indices_analysis'].items()):\n",
        "                f.write(f\"  Batch {batch}: {data['total_zero_weights']} total zero weights\\n\")\n",
        "\n",
        "            # Add trends\n",
        "            batches = sorted(tiny_results['zero_indices_analysis'].keys())\n",
        "            if len(batches) > 1:\n",
        "                f.write(\"\\nTrends in zero weights:\\n\")\n",
        "                for i in range(len(batches)-1):\n",
        "                    curr_batch = batches[i]\n",
        "                    next_batch = batches[i+1]\n",
        "                    curr_zeros = tiny_results['zero_indices_analysis'][curr_batch]['total_zero_weights']\n",
        "                    next_zeros = tiny_results['zero_indices_analysis'][next_batch]['total_zero_weights']\n",
        "                    diff = next_zeros - curr_zeros\n",
        "\n",
        "                    if diff > 0:\n",
        "                        f.write(f\"  Batch {curr_batch} → {next_batch}: +{diff} weights became zero\\n\")\n",
        "                    elif diff < 0:\n",
        "                        f.write(f\"  Batch {curr_batch} → {next_batch}: {diff} zero weights became non-zero\\n\")\n",
        "                    else:\n",
        "                        f.write(f\"  Batch {curr_batch} → {next_batch}: No change in zero weights\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        # f.write(\"MEDIUM PRUNING TEST (30%)\\n\")\n",
        "        # f.write(\"-------------------------\\n\")\n",
        "        # if medium_results['all_matching']:\n",
        "        #     f.write(\"PASS: All pruned indices remain zero across all batch updates\\n\")\n",
        "        # else:\n",
        "        #     f.write(\"FAIL: Some pruned indices changed during training\\n\")\n",
        "        #     for comp in medium_results.get('comparisons', []):\n",
        "        #         if not comp.get('matching', False):\n",
        "        #             f.write(f\"  Batch {comp.get('batch')}: Verification failed\\n\")\n",
        "        #             for error in comp.get('errors', []):\n",
        "        #                 f.write(f\"    {error}\\n\")\n",
        "\n",
        "        # # Add analysis of zero indices across batches for medium pruning\n",
        "        # if 'zero_indices_analysis' in medium_results and len(medium_results['zero_indices_analysis']) > 0:\n",
        "        #     f.write(\"\\nAnalysis of ALL zero weights across batches:\\n\")\n",
        "        #     for batch, data in sorted(medium_results['zero_indices_analysis'].items()):\n",
        "        #         f.write(f\"  Batch {batch}: {data['total_zero_weights']} total zero weights\\n\")\n",
        "\n",
        "        #     # Add trends\n",
        "        #     batches = sorted(medium_results['zero_indices_analysis'].keys())\n",
        "        #     if len(batches) > 1:\n",
        "        #         f.write(\"\\nTrends in zero weights:\\n\")\n",
        "        #         for i in range(len(batches)-1):\n",
        "        #             curr_batch = batches[i]\n",
        "        #             next_batch = batches[i+1]\n",
        "        #             curr_zeros = medium_results['zero_indices_analysis'][curr_batch]['total_zero_weights']\n",
        "        #             next_zeros = medium_results['zero_indices_analysis'][next_batch]['total_zero_weights']\n",
        "        #             diff = next_zeros - curr_zeros\n",
        "\n",
        "        #             if diff > 0:\n",
        "        #                 f.write(f\"  Batch {curr_batch} → {next_batch}: +{diff} weights became zero\\n\")\n",
        "        #             elif diff < 0:\n",
        "        #                 f.write(f\"  Batch {curr_batch} → {next_batch}: {diff} zero weights became non-zero\\n\")\n",
        "        #             else:\n",
        "        #                 f.write(f\"  Batch {curr_batch} → {next_batch}: No change in zero weights\\n\")\n",
        "        #                 f.write(\"\\n\")\n",
        "\n",
        "        # f.write(\"CONCLUSION\\n\")\n",
        "        # f.write(\"----------\\n\")\n",
        "        # if tiny_results['all_matching'] and medium_results['all_matching']:\n",
        "        #     f.write(\"The DenseNet pruning implementation is working correctly.\\n\")\n",
        "        #     f.write(\"All pruned weights remain zero during training as expected.\\n\")\n",
        "        #     f.write(\"\\nNote: You may have seen warnings about 'pruned weights became non-zero'.\\n\")\n",
        "        #     f.write(\"This is normal and expected. These warnings indicate that gradient updates\\n\")\n",
        "        #     f.write(\"tried to change pruned weights, but our MaskWeightsCallback detected this\\n\")\n",
        "        #     f.write(\"and re-applied the mask to set them back to zero. The verification files\\n\")\n",
        "        #     f.write(\"confirm that all pruned weights remained zero after the callback ran.\\n\")\n",
        "\n",
        "        #     # Add insights from zero weights analysis\n",
        "        #     f.write(\"\\nADDITIONAL INSIGHTS FROM ALL-ZERO-INDICES ANALYSIS:\\n\")\n",
        "        #     if 'zero_indices_analysis' in tiny_results and 'zero_indices_analysis' in medium_results:\n",
        "        #         # Check if number of zero weights increases during training\n",
        "        #         tiny_batches = sorted(tiny_results['zero_indices_analysis'].keys())\n",
        "        #         if len(tiny_batches) > 1:\n",
        "        #             first = tiny_batches[0]\n",
        "        #             last = tiny_batches[-1]\n",
        "        #             if tiny_results['zero_indices_analysis'][last]['total_zero_weights'] > tiny_results['zero_indices_analysis'][first]['total_zero_weights']:\n",
        "        #                 f.write(\"- In the tiny pruning test, the number of zero weights increased during training.\\n\")\n",
        "        #                 f.write(\"  This suggests that the training process is naturally driving some weights to zero.\\n\")\n",
        "\n",
        "        #         medium_batches = sorted(medium_results['zero_indices_analysis'].keys())\n",
        "        #         if len(medium_batches) > 1:\n",
        "        #             first = medium_batches[0]\n",
        "        #             last = medium_batches[-1]\n",
        "        #             if medium_results['zero_indices_analysis'][last]['total_zero_weights'] > medium_results['zero_indices_analysis'][first]['total_zero_weights']:\n",
        "        #                 f.write(\"- In the medium pruning test, the number of zero weights increased during training.\\n\")\n",
        "        #                 f.write(\"  This is normal behavior and indicates that the network is becoming more sparse\\n\")\n",
        "        #                 f.write(\"  as training progresses, which can improve efficiency without sacrificing performance.\\n\")\n",
        "        # else:\n",
        "        #     f.write(\"ISSUES DETECTED: The pruning implementation may have problems.\\n\")\n",
        "        #     f.write(\"Some pruned weights did not remain zero during training.\\n\")\n",
        "        #     f.write(\"Please review the verification files for details.\\n\")\n",
        "\n",
        "        f.write(\"\\nFor a detailed analysis:\\n\")\n",
        "        if GOOGLE_DRIVE_MOUNTED:\n",
        "            f.write(f\"1. Download the files from Google Drive at {GOOGLE_DRIVE_BASE_PATH}\\n\")\n",
        "        else:\n",
        "            f.write(f\"1. Upload the {output_dir} directory to a Linux machine\\n\")\n",
        "        f.write(\"2. Run the compare_indices.sh script\\n\")\n",
        "        f.write(\"3. Examine the all-zero-indices_batch-*.txt files to see all weights that are zero at each batch\\n\")\n",
        "        f.write(\"4. CSV files of all zero indices are also available for easier processing in other tools\\n\")\n",
        "\n",
        "    print(f\"\\nVerification report created: {report_path}\")\n",
        "    # if GOOGLE_DRIVE_MOUNTED:\n",
        "    #     print(f\"Report is available in your Google Drive at: {GOOGLE_DRIVE_BASE_PATH}\")\n",
        "\n",
        "    # if tiny_results['all_matching'] and medium_results['all_matching']:\n",
        "    #     print(\"OVERALL RESULT: PASS - Pruning is working correctly\")\n",
        "    #     print(\"\\nNOTE: Despite the warnings about non-zero weights during training,\")\n",
        "    #     print(\"the mask callback properly resets them to zero. Your implementation is working correctly.\")\n",
        "    # else:\n",
        "    #     print(\"OVERALL RESULT: FAIL - Issues detected with pruning implementation\")\n",
        "\n",
        "    # Final check: If files weren't found where expected, run a file search\n",
        "    if not os.path.exists(os.path.join(tiny_pruning_dir, \"all-zero-indices_batch-0.txt\")) or \\\n",
        "       not os.path.exists(os.path.join(medium_pruning_dir, \"all-zero-indices_batch-0.txt\")):\n",
        "        print(\"\\nWARNING: Some expected files were not found where expected.\")\n",
        "        print(\"Running a file search to locate verification files...\")\n",
        "        found_files = find_verification_files()\n",
        "\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    # Print information about file storage\n",
        "    if GOOGLE_DRIVE_MOUNTED:\n",
        "        print(f\"Google Drive is mounted. All verification files will be saved to:\")\n",
        "        print(f\"  {GOOGLE_DRIVE_BASE_PATH}\")\n",
        "\n",
        "        # Test Google Drive write access\n",
        "        test_file = os.path.join(GOOGLE_DRIVE_BASE_PATH, \"write_test.txt\")\n",
        "        try:\n",
        "            with open(test_file, 'w') as f:\n",
        "                f.write(\"This is a test to verify write permissions to Google Drive\")\n",
        "            print(\"Successfully wrote test file to Google Drive. File access is working correctly.\")\n",
        "            os.remove(test_file)  # Clean up test file\n",
        "        except Exception as e:\n",
        "            print(f\"WARNING: Failed to write test file to Google Drive: {str(e)}\")\n",
        "            print(\"Files may not be properly saved. Consider running locally or fixing Drive permissions.\")\n",
        "    else:\n",
        "        print(\"Google Drive is not mounted. Files will be saved locally.\")\n",
        "        print(\"To save files to Google Drive, run this script in Google Colab.\")\n",
        "\n",
        "    verify_densenet_pruning_comprehensive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ha-I4aYE5nvg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}